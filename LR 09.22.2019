import numpy as np
import pandas as pd
import scipy as sp
import matplotlib.pyplot as mp

# Logistic regression model
# P(y=1|x)=1/(1+e^-a)
# P(y=0|x)=1-1/(1+e^-a)=(e^-a)/(1-e^-a)
# a=ln(P(y=1|x)/P(y=0|x))=ln1-ln(e^-a)

class LogisticRegression:


    def __init__(self, w):
        self.w = w


    # initializing parameter array
    def initialization_w(self, n):
        w = np.zeros((1, n))
        return w


    # predict the target from given A=wTx
    def logistic(self, a):
        # The mapping of the function is in [0,1]
        return 1 / (1 + np.exp(-a))


    # logistic function
    # def derivative_logistic(self, a):
    #    return self.logistic(a) * (1 - self.logistic(a))


    # Computing wTx
    def information_matrix(self, w, x):
        return np.dot(w, x)


    # Compute the probability value
    def result_from_logistic(self, w, x):  # probability function
        return self.logistic(self.information_matrix(w, x))


    # Our Error function
    def cross_entropy(self, w, X, y):  # y=0,1
        # Here is our cost function
        lost = 0
        for i in range(len(X.index)):
            lost += - (y[i] * np.log(self.result_from_logistic(w, np.array(X.loc[i])))
                       + (1 - y[i]) * np.log(1 - self.result_from_logistic(w, np.array(X.loc[i]))))

        return lost


    # gradient of error function
    def gradient_cross_entropy(self, w, X, y):
        # Later for the gradient descent
        # Compute gradient at a certain point w
        gradient_at_w = np.zeros_like(self.w)
        for i in range(len(X.index)):
            gradient_at_w += - (np.array(X.loc[i]) * (y[i] - self.result_from_logistic(w, np.array(X.loc[i]))))

        return gradient_at_w


    # # Initialization of learning rate alpha
    # def initialization_learning_rate(self):
    #     rate = 0.05
    #     return rate
    #
    #
    # # Initialization of iteration
    # def initialization_iteration(self):
    #     iteration = 50000
    #     return iteration


    # old fit function
    #  def gradient_descent(x, y):
    #    w = np.ones_like(x)  # Initialize w0
    #    a = initialization_learning_rate()
    #
    #    difference = 1.0
    #    min_difference = 0.0001  # difference between w and w'

    #    max_iteration = 50000  # in case of the function does not converge
    #    iteration_counter = 0
    #    gradient = gradient_cross_entropy(w, x, y)
    #
    #    while iteration_counter <= max_iteration and difference >= min_difference:
    #        store_w = w
    #        w = w - a * gradient_cross_entropy(w, x, y)
    #        difference = abs(w - store_w)
    #        iteration_counter = iteration_counter+1
    #        print(iteration_counter, "iteration", " w-updated: ", w)


    # Gradient descent, we are updating w, started from randomly generated w0=[0,100]
    # w=w'-(learning rate)*gradient of error function
    # gradient descent step
    def fit(self, X, y, learning_rate=0.05, iteration=50000):
        iteration_counter = 0
        cross_en = []

        while iteration_counter <= iteration:
            store_w = self.w
            gradient = self.gradient_cross_entropy(store_w, X, y)

            cost = self.cross_entropy(store_w, X, y)
            cross_en.append(cost)

            self.w = store_w - learning_rate * gradient  # updating parameters
            iteration_counter = iteration_counter + 1

        return self.w, cross_en


    # predicting the data points
    def predict(self, X):
        log_odds_ratio_list = np.zeros((1, len(X.index)))
        for i in range(len(X.index)):
            log_odds_ratio_list[i] = np.log((self.result_from_logistic(self.w, np.array(X.loc[i]))) /
                                            (1-self.result_from_logistic(self.w, np.array(X.loc[i]))))
            log_odds_ratio_list[i] = [0 if log_odds_ratio_list[i] < 0.5 else 1]

        return log_odds_ratio_list


    def evaluate_acc(X, y, log_odds_ratio_list):
        difference = np.array(np.array(y) - np.array(log_odds_ratio_list))
        acc = 0
        for i in difference:
            if i != 0:
                acc += 1

        return acc / (len(difference) * 1.0)
