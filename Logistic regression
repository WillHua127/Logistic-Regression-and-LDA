import numpy as np
import pandas as pd
import scipy as sp
import matplotlib.pyplot as mp

# Logistic regression model
# P(y=1|x)=1/(1+e^-a)
# P(y=0|x)=1-1/(1+e^-a)=(e^-a)/(1-e^-a)
# a=ln(P(y=1|x)/P(y=0|x))=ln1-ln(e^-a)


# initializing parameter array
def initialization_w(n):
    w = np.zeros((1, n))
    return w


# predict the target from given A=wTx
def logistic(a):
    # The mapping of the function is in [0,1]
    return 1 / (1 + np.exp(-a))


# logistic function
def derivative_logistic(a):
    return logistic(a) * (1 - logistic(a))


# Computing wTx
def information_matrix(w, x, w0):
    return np.dot(w.T, x) + w0


# Compute the probability value
def result_from_logistic(w, x, w0):  # probability function
    return logistic(information_matrix(w, x, w0))


# Our Error function
def cross_entropy(w, x, y, w0):  # y=0,1
    # Here is our cost function
    lost = - np.sum(y * np.log(result_from_logistic(w, x, w0)) + (1 - y) * np.log(1 - result_from_logistic(w, x, w0)))
    return lost


# gradient of error function
def gradient_cross_entropy(w, x, y, w0):
    # Later for the gradient descent
    # Compute gradient at a certain point w
    gradient_at_w = - np.sum(x(y - result_from_logistic(w, x, w0)))
    return gradient_at_w


# Initialization of learning rate alpha
def initialization_learning_rate():
    rate = 0.05
    return rate


# Initialization of iteration
def initialization_iteration():
    iteration = 50000
    return iteration


# old fit function
#  def gradient_descent(x, y):
#    w = np.ones_like(x)  # Initialize w0
#    a = initialization_learning_rate()
#
#    difference = 1.0
#    min_difference = 0.0001  # difference between w and w'

#    max_iteration = 50000  # in case of the function does not converge
#    iteration_counter = 0
#    gradient = gradient_cross_entropy(w, x, y)
#
#    while iteration_counter <= max_iteration and difference >= min_difference:
#        store_w = w
#        w = w - a * gradient_cross_entropy(w, x, y)
#        difference = abs(w - store_w)
#        iteration_counter = iteration_counter+1
#        print(iteration_counter, "iteration", " w-updated: ", w)


def optimization(w, x, y):
    opt = sp.fmin(func=cross_entropy, x0=w, fprime=gradient_cross_entropy, args=(x.flatten(), y.flatten()))
    return opt


# Gradient descent, we are updating w, started from randomly generated w0=[0,100]
# w=w'-(learning rate)*gradient of error function
# gradient descent step
def fit(w, x, y, w0, learning_rate=initialization_learning_rate(), iteration=initialization_iteration()):
    difference = 1.0
    min_difference = 0.0001  # difference between w and w'
    iteration_counter = 0
    cross_en = []

    while iteration_counter <= iteration and difference >= min_difference:
        gradient = gradient_cross_entropy(w, x, y, w0)
        cost = cross_entropy(w, x, y, w0)
        store_w = w

        w = w - learning_rate * gradient  # making parameters
        w0 = w0 - learning_rate * gradient  # making constant
        cross_en.append(cost)

        difference = abs(w - store_w)
        iteration_counter = iteration_counter + 1

    para = {"w": w, "w0": w0}
    return para, cross_en


# predicting the data points question!!!!!!!
def predict(x, y):
    prediction = np.zeros((1, y.shape[1]))
    for i in range(y.shape[1]):
        if prediction[0][i] > 0.5:
            y_pred[0][i] = 1
    return prediction
