import numpy as np
import pandas as pd
import scipy as sp
import matplotlib.pyplot as mp

# Linear discriminant analysis model
# Compute log-odds ratio
# Decision boundary, log-odds ratio>0, then output is 1; 0 otherwise

class LDA:


    # P(y=0)
    def probability_c1(self, n0, n1):
        return n1/(n0+n1)


    # P(y=1)
    def probability_c0(self, n0, n1):
        return n0/(n0+n1)


    # Mu1, if object from class1 contains feature xi, then i=1; 0 otherwise
    def mean_c1(self, X):
        sum_class1 = np.zeros_like(X[0], float)
        for i in range(len(X)):
            sum_class1 += np.array(X[i])

        return sum_class1 / len(X)


    # Mu0, if object from class0 contains feature xi, then i=1; 0 otherwise
    def mean_c0(self, X):
        sum_class0 = np.zeros_like(X[0], float)
        for i in range(len(X)):
            sum_class0 += np.array(X[i])

        return sum_class0 / len(X)


    # when class0
    def covariance_c0(self, X):
        sum0 = 0
        for i in range(len(X)):
            difference = np.array(X[i]) - self.mean_c0(X)
            sum0 += np.dot(difference, difference)

        return sum0


    # when class1
    def covariance_c1(self, X):
        sum1 = 0
        for i in range(len(X)):
            difference = np.array(X[i]) - self.mean_c1(X)
            sum1 += np.dot(difference, difference)

        return sum1

    # sum up two covariance
    def covariance(self, X1, X0):
        covar0 = self.covariance_c0(X1)
        covar1 = self.covariance_c1(X0)
        covar = (covar0 + covar1)/(len(X1) + len(X0) - 2)

        return covar


    # computing log-odds ratio
    def fit(self, X, y):
        class1 = []
        class0 = []
        log_odds_ratio_list = []

        for i in range(len(X.index)):
            if y[i] == 1:
                class1.append(np.array(X.loc[i]))
            elif y[i] == 0:
                class0.append(np.array(X.loc[i]))

        ratio = np.log(self.probability_c1(len(class0), len(class1))/self.probability_c0(len(class0), len(class1)))
        mu1 = self.mean_c1(class1)
        mu0 = self.mean_c0(class0)
        covar = self.covariance(class1, class0)
        in_covar = np.linalg.inv(covar)
        w0 = ratio - (np.dot(mu1, mu1) * in_covar)/2 + (np.dot(mu0, mu0) * in_covar)/2

        for i in range(len(X.index)):
            xTw = np.dot((mu1 - mu0), np.array(X.loc[i])) * in_covar
            log_odds_ratio = w0 + xTw
            log_odds_ratio_list.append(log_odds_ratio)

        return log_odds_ratio_list


    # predicting single data point
    def predict(self, X, y):
        prediction = np.array(self.fit(X, y))
        for i in range(len(X.index)):
            prediction[i] = [0 if prediction[i] < 0.5 else 1]

        return prediction


    # accuracy function
    def evaluate_acc(X, y, prediction_y):
        difference = np.array(np.array(y) - np.array(prediction_y))
        acc = 0
        for diff in difference:
            if diff != 0:
                acc += 1

        return acc / (len(difference) * 1.0)
